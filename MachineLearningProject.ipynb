{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebisunti/Prova/blob/main/MachineLearningProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jDBR7kyywx2"
      },
      "source": [
        "## Install libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A3otcPC9xYL",
        "outputId": "21c65b91-31de-40b4-ef9f-7765881ae12d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n",
            "Collecting swig\n",
            "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.1.1\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.1.1)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2373076 sha256=c57354db9a2c586e81527fcb8721f661ac682503c07a345f04ebc240efb119f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n",
            "Collecting gym-notebook-wrapper\n",
            "  Downloading gym_notebook_wrapper-1.3.3-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from gym-notebook-wrapper) (0.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gym-notebook-wrapper) (3.7.1)\n",
            "Collecting pyvirtualdisplay (from gym-notebook-wrapper)\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from gym-notebook-wrapper) (7.34.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from gym-notebook-wrapper) (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym->gym-notebook-wrapper) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->gym-notebook-wrapper) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->gym-notebook-wrapper) (0.0.8)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->gym-notebook-wrapper)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (4.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (2.8.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (0.4.9)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->gym-notebook-wrapper) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->gym-notebook-wrapper) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->gym-notebook-wrapper) (0.2.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->gym-notebook-wrapper) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->gym-notebook-wrapper) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->gym-notebook-wrapper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->gym-notebook-wrapper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->gym-notebook-wrapper) (2023.7.22)\n",
            "Installing collected packages: pyvirtualdisplay, jedi, gym-notebook-wrapper\n",
            "Successfully installed gym-notebook-wrapper-1.3.3 jedi-0.19.1 pyvirtualdisplay-3.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 7,814 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.2 [28.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.2 [864 kB]\n",
            "Fetched 7,814 kB in 1s (14.1 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 120874 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.2_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.2_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Collecting xvfbwrapper\n",
            "  Downloading xvfbwrapper-0.2.9.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: xvfbwrapper\n",
            "  Building wheel for xvfbwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xvfbwrapper: filename=xvfbwrapper-0.2.9-py3-none-any.whl size=5009 sha256=45ffaa8c1e43ed2f9cdf6e084ae15063870c7ce1fa4576781b5471b89fe5808d\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/10/7d/2b7fdffccf837f7d5425931575fbee9caebe2c190931f9058b\n",
            "Successfully built xvfbwrapper\n",
            "Installing collected packages: xvfbwrapper\n",
            "Successfully installed xvfbwrapper-0.2.9\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install swig     #This solves the errori in the installation of gymnasium[box2d]\n",
        "!pip install gymnasium[box2d]\n",
        "!pip install gym-notebook-wrapper   #This installs Gym-Notebook-Wrapper, that provides small wrappers for running and rendering OpenAI Gym\n",
        "\n",
        "#To solve the xvfb missing file problem\n",
        "!sudo apt-get install xvfb\n",
        "!pip install xvfbwrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lCpyHIx0K0w"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IW5i1FfF0PeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3926123-0938-470e-f676-443f8dc9a36b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MachineLearningProject'...\n",
            "remote: Enumerating objects: 264, done.\u001b[K\n",
            "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 264 (delta 80), reused 0 (delta 0), pack-reused 135\u001b[K\n",
            "Receiving objects: 100% (264/264), 1006.66 KiB | 7.46 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n",
            "/content/MachineLearningProject\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Federico6419/MachineLearningProject          #It clones my github repository\n",
        "%cd MachineLearningProject\n",
        "\n",
        "import gymnasium as gym\n",
        "import gnwrapper\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import config\n",
        "from model import Model\n",
        "from collections import deque\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F"
      ],
      "metadata": {
        "id": "MKJKM9g2pV6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive                                   #This is commented because we used to save or load our results using our Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "episode_reward = 0\n",
        "tot_negative_reward = 0\n",
        "time_frame_counter = 1\n",
        "buffer = deque([], config.BUFFER_SIZE)             #Initialize the Queue that contains the past experience\n",
        "epsilon = config.MAX_EPSILON\n",
        "if(config.LOAD_CHECKPOINT):\n",
        "    epsilon = config.LOADED_EPSILON\n",
        "\n",
        "alpha = config.ALPHA\n",
        "decay = config.EPSILON_DECAY\n",
        "\n",
        "#For the plotting\n",
        "cum_reward_table = np.zeros(config.NUM_EPISODES)\n",
        "cum_reward_nn = np.zeros(config.NUM_EPISODES)\n",
        "\n",
        "#Initialize the Model\n",
        "model = Model().to(config.DEVICE)\n",
        "\n",
        "#Initialize the Target Model\n",
        "target_model = Model().to(config.DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.LR)\n",
        "optimizer_target = optim.Adam(target_model.parameters(), lr=config.LR)\n",
        "\n",
        "if(config.LOAD_CHECKPOINT):\n",
        "    config.load_model(config.LOAD_CHECKPOINT_FOLDER,model,optimizer)\n",
        "    config.load_model(config.LOAD_CHECKPOINT_FOLDER,target_model,optimizer_target)\n",
        "\n",
        "#huber_loss=nn.HuberLoss(delta=1.0)\n",
        "mean_squared_error = torch.nn.MSELoss()\n",
        "\n",
        "#Define the Action Space\n",
        "action_space = [\n",
        "                (-1, 1, 0.2), (0, 1, 0.2), (1, 1, 0.2),\n",
        "                (-1, 1,   0), (0, 1,   0), (1, 1,   0),               #(Steering Wheel, Gas, Break)\n",
        "                (-1, 0, 0.2), (0, 0, 0.2), (1, 0, 0.2),               #Range -1~1 0~1 0~1\n",
        "                (-1, 0,   0), (0, 0,   0), (1, 0,   0)\n",
        "              ]\n",
        "\n",
        "#Define the policy to know how chose the action\n",
        "#Q-Table\n",
        "def select_action(state, epsilon):\n",
        "    rv = random.uniform(0, 1)\n",
        "    if rv < epsilon:\n",
        "        return env.action_space.sample()\n",
        "    else:\n",
        "        return np.argmax(Q[state])\n",
        "\n",
        "#Neural Network\n",
        "def select_action_nn(state, epsilon):\n",
        "    rv = random.uniform(0, 1)\n",
        "    if rv < epsilon:\n",
        "        return action_space[random.randrange(len(action_space))]          #We sample a random action\n",
        "\n",
        "    else:\n",
        "        prediction = model(torch.from_numpy(state.astype('float32')).to(config.DEVICE)).detach().cpu().numpy()\n",
        "        action = action_space[np.argmax(prediction)]              #Select the action with the maximum predicted Q-Value\n",
        "\n",
        "        return action\n",
        "\n",
        "\n",
        "## update the epsilon value along the iteration until converges to MIN_EPSILON\n",
        "def update_epsilon(epsilon):\n",
        "    epsilon -= epsilon/100 # reduce epsilon by 1/100\n",
        "    if epsilon<=config.MIN_EPSILON:\n",
        "        return config.MIN_EPSILON\n",
        "    else:\n",
        "        return epsilon\n",
        "\n",
        "## update the epsilon every episode by epsilon decay variable\n",
        "def update_epsilon_nn(epsilon):\n",
        "    epsilon *= decay\n",
        "    if epsilon<=config.MIN_EPSILON:\n",
        "        return config.MIN_EPSILON\n",
        "    else:\n",
        "        return epsilon\n",
        "\n",
        "\n",
        "env = gym.make(\"CarRacing-v2\", render_mode=\"human\")\n",
        "\n",
        "\n",
        "if(config.USE_QTABLE):\n",
        "    # define the Q table\n",
        "    #Q = np.zeros([27684, env.action_space.n]) # little discretization\n",
        "    Q = np.zeros([19051200, env.action_space.n]) #big discretization\n",
        "\n",
        "###see the limit of the values of the box observation space\n",
        "#print(env.observation_space.high)\n",
        "#print(env.observation_space.low)\n",
        "\n",
        "###see in more detail the action space and the observation space\n",
        "#print(env.action_space)\n",
        "#print(env.observation_space)\n",
        "\n",
        "\n",
        "if(config.USE_QTABLE): # use a q table to reach the goal\n",
        "    for i in range(config.NUM_EPISODES):\n",
        "        observation, info = env.reset()# use seed to have same initial state\n",
        "        #state = config.discretize(observation)\n",
        "        state = config.big_discretize(observation)\n",
        "\n",
        "        for j in range(500):\n",
        "            action = select_action(state,epsilon)\n",
        "            obv, reward, done, truncated, info = env.step(action)\n",
        "            #next_state = config.discretize(obv)\n",
        "            next_state = config.big_discretize(obv)\n",
        "\n",
        "            next_max = np.max(Q[next_state])\n",
        "\n",
        "            Q[state,action] += alpha*(reward+config.GAMMA*next_max-Q[state,action])\n",
        "            state = next_state\n",
        "\n",
        "            episode_reward += reward\n",
        "\n",
        "            if done or truncated:\n",
        "                break\n",
        "\n",
        "        print(\"episode: \", i)\n",
        "        print(\"episode cumulative reward : \", episode_reward)\n",
        "        print(\"epsilon: \",epsilon)\n",
        "        epsilon = update_epsilon(epsilon)\n",
        "        cum_reward_table[i]=episode_reward\n",
        "        episode_reward = 0 #reset the total reward each episode\n",
        "\n",
        "    #save the q table for testing\n",
        "    #np.savetxt('q_table.csv', Q, delimiter=','fmt='%f18')\n",
        "    #np.savetxt('q_table_little_discretization2000.csv', Q, delimiter=',') # full precision\n",
        "    np.savetxt('q_table_big_discretization1000.csv', Q, delimiter=',') # full precision\n",
        "\n",
        "else:             #Use a Neural Network to approximate the Q Function\n",
        "    for i in range(config.NUM_EPISODES):\n",
        "        state, info = env.reset()               #The state is a 96x96 Matrix, that contains elements composed by 3 Colours RGB\n",
        "        state = cv2.cvtColor(state, cv2.COLOR_BGR2GRAY)           #Convert the state into a Grayscale Image, that is a Matrix 96x96 composed by Integer values\n",
        "        #state = state.astype(float)\n",
        "        #state /= 255.0\n",
        "\n",
        "        frames_queue = deque([state]*3, maxlen = 3)\n",
        "\n",
        "        done = False\n",
        "\n",
        "        while(True):\n",
        "\n",
        "            current_frame = np.array(frames_queue)\n",
        "\n",
        "            action = select_action_nn(current_frame, epsilon)                      #The Action is composed by 3 Values, that are the steering, gas and breaking\n",
        "\n",
        "            rew = 0\n",
        "            #Skip Frames\n",
        "            for tot in range(3):\n",
        "                next_state, reward, done, truncated, info = env.step(action)\n",
        "                rew += reward\n",
        "                if done or truncated:\n",
        "                    break\n",
        "\n",
        "            # If continually getting negative reward 10 times after the tolerance steps, terminate this episode\n",
        "            tot_negative_reward = tot_negative_reward + 1 if time_frame_counter > 100 and reward < 0 else 0\n",
        "\n",
        "\n",
        "            # Extra bonus for the model if it uses full gas\n",
        "            if action[1] == 1 and action[2] == 0:\n",
        "                rew *= 1.5\n",
        "\n",
        "            episode_reward += rew\n",
        "\n",
        "            next_state = cv2.cvtColor(next_state, cv2.COLOR_BGR2GRAY)\n",
        "            #Add normalization?\n",
        "\n",
        "            frames_queue.append(next_state)\n",
        "            next_frame = np.array(frames_queue)\n",
        "\n",
        "            #Remove the oldest item if the queue is full, in a way such that we can add a new one\n",
        "            if len(buffer)>=config.BUFFER_SIZE:\n",
        "                buffer.popleft()               #We dequeue the oldest item\n",
        "\n",
        "            #buffer.append([*state,action,reward,*next_state,done])\n",
        "            buffer.append((current_frame, action_space.index(action), reward, next_frame, done))\n",
        "            #buffer.append([*current_frame, action_space.index(action), reward, *next_frame, done])\n",
        "\n",
        "            if done or truncated:    # or tot_negative_reward > 25 or episode_reward < 0:\n",
        "                epsilon = update_epsilon_nn(epsilon)\n",
        "                print(\"episode \", i)\n",
        "                print(\"episode cumulative reward: \", episode_reward)\n",
        "                print(\"current epsilon: \", epsilon)\n",
        "                print(\"#---------------------------------------------#\")\n",
        "                break\n",
        "\n",
        "            #Let's train the Neural Network every 4 actions and if the buffer has at least BATCH_SIZE elements\n",
        "            #if((len(buffer) >= config.BATCH_SIZE) and ((j+1) % 4 == 0)):\n",
        "            if(len(buffer) >= config.BATCH_SIZE):\n",
        "                batch = random.sample(buffer, config.BATCH_SIZE)\n",
        "                #data = np.array(batch)\n",
        "\n",
        "                output_array = []\n",
        "                target_array = []\n",
        "\n",
        "                for current_frame, action, reward, next_frame, done in batch:\n",
        "\n",
        "                    #VECCHIO MODO\n",
        "                    # Find next best action using model network\n",
        "                    #next_frame = torch.from_numpy(next_frame.astype('float32')).to(config.DEVICE)\n",
        "                    #predictions_next = model(next_frame).detach().cpu().numpy()\n",
        "                    #current_frame = torch.from_numpy(current_frame.astype('float32')).to(config.DEVICE)\n",
        "                    #predictions_next = model(current_frame).detach().cpu().numpy()\n",
        "\n",
        "                    #next_frame = torch.from_numpy(next_frame.astype('float32')).to(config.DEVICE)\n",
        "                    #t = target_model(next_frame)\n",
        "                    #predictions_next[action] = reward + config.GAMMA * max(t)\n",
        "\n",
        "                    #compute the predicted value of the model(output)\n",
        "                    #output = model(current_frame)\n",
        "                    #output =  output[..., np.newaxis]\n",
        "                    #predictions_next =  predictions_next[..., np.newaxis]\n",
        "                    #predictions_next = torch.from_numpy(predictions_next).to(config.DEVICE)\n",
        "                    #loss = huber_loss(output, predictions_next)\n",
        "                    #loss = mean_squared_error(output, predictions_next)\n",
        "\n",
        "                    #NUOVO MODO\n",
        "                    next_frame = torch.from_numpy(next_frame.astype('float32')).to(config.DEVICE)\n",
        "                    next_frame = target_model(next_frame).detach()\n",
        "                    target = reward + (1 - done) * config.GAMMA * max(next_frame)#next_frame.max(dim=1, keepdim=True).values\n",
        "                    #target = reward + config.GAMMA * max(next_frame)\n",
        "\n",
        "                    target_array.append(target)\n",
        "\n",
        "                    current_frame = torch.from_numpy(current_frame.astype('float32')).to(config.DEVICE)\n",
        "                    output = model(current_frame)\n",
        "\n",
        "                    output_array.append(output[action])\n",
        "\n",
        "                target_array = torch.tensor(target_array).to(config.DEVICE)\n",
        "                output_array = torch.tensor(output_array).to(config.DEVICE)\n",
        "\n",
        "                #loss = mean_squared_error(output[action], target)\n",
        "                loss = mean_squared_error(output_array, target_array)\n",
        "                loss.requires_grad=True\n",
        "\n",
        "                #Train network\n",
        "                optimizer.zero_grad()#clear existing gradient\n",
        "                loss.backward() #backpropagate the error\n",
        "                optimizer.step() # update weights\n",
        "\n",
        "            time_frame_counter += 1\n",
        "\n",
        "\n",
        "        if (i+1) % 5 == 0:\n",
        "            #save the weight of the network\n",
        "            config.save_model(model,optimizer,i+1)\n",
        "            torch.save({\n",
        "                \"state_dict\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "            }, \"../drive/MyDrive/Checkpoint\")\n",
        "            print(\"Save weigths in: \"+ config.CHECKPOINT_FOLDER)\n",
        "\n",
        "        if (i+1) % 5 == 0:\n",
        "            #update weights of target network every 10 actions\n",
        "            print(\"Target network updated\")\n",
        "            config.load_model(config.CHECKPOINT_FOLDER,target_model,optimizer_target)\n",
        "\n",
        "\n",
        "        cum_reward_nn[i]=episode_reward\n",
        "        episode_reward = 0\n",
        "        tot_negative_reward = 1\n",
        "        time_frame_counter = 1\n",
        "\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OTI2zOGcpXiu",
        "outputId": "52318611-6c1a-47ba-d6c1-c2f20e95ca78"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "tensor([20.2394, 21.0994, 22.9894, 25.5311, 20.9416, 20.9164, 21.0627, 21.1051,\n",
            "        21.8900, 20.8000, 20.9054, 21.7680, 21.0890, 21.5693, 20.7405, 20.9593,\n",
            "        25.2447, 21.1059, 21.0033, 21.0859, 20.5221, 20.0820, 21.3934, 20.2058,\n",
            "        20.9205, 20.8119, 21.1942, 20.2105, 20.2244, 20.8597, 21.0679, 21.1004,\n",
            "        21.0669, 20.2720, 21.2468, 21.4101, 21.1667, 20.1365, 21.0779, 20.8281,\n",
            "        21.5506, 21.1701, 21.1301, 24.0024, 21.3526, 21.0068, 21.0566, 21.1033,\n",
            "        21.6814, 21.0326, 21.2451, 20.1058, 22.7287, 20.8001, 20.9804, 20.9300,\n",
            "        21.0668, 21.3560, 21.3354, 21.0535, 20.9488, 20.2704, 20.2159, 20.1332],\n",
            "       device='cuda:0')\n",
            "tensor([-6.3347e+00, -4.4375e+00,  3.9162e+00, -4.4711e+00, -3.1205e-01,\n",
            "        -7.0593e+00,  4.1571e+00, -5.6349e+00, -1.5124e+01, -5.8556e+00,\n",
            "        -2.5513e-01,  4.6471e+00,  7.1081e+00,  6.7919e-01, -4.4511e+00,\n",
            "        -2.8066e+00, -6.8069e+00,  3.7727e+00,  4.1272e+00, -2.9926e-01,\n",
            "        -4.4079e+00,  1.2761e+00,  1.1469e+01,  4.6023e+00,  4.1716e+00,\n",
            "        -2.6625e+00, -6.7492e+00, -1.2195e+01, -6.6740e+00, -7.0731e+00,\n",
            "         4.0113e+00,  4.2162e-03,  3.8419e+00, -1.6522e+00, -6.9088e+00,\n",
            "        -4.5593e+00, -7.1949e+00, -6.9858e+00, -6.5904e+00, -8.5625e-01,\n",
            "        -7.4286e+00, -6.8292e+00, -2.7313e+00, -1.3654e+01, -1.2835e+01,\n",
            "        -3.1044e+00, -6.6738e+00, -4.5748e+00,  4.1273e+00, -4.3071e+00,\n",
            "        -6.6522e+00, -4.7291e+00,  4.8435e+00,  1.8745e+00,  1.0248e+01,\n",
            "        -6.8322e+00,  9.8798e+00, -1.1763e+01,  7.1610e+00, -6.4305e+00,\n",
            "        -5.7088e+00, -6.5521e+00, -5.1248e+00,  1.0965e+00], device='cuda:0')\n",
            "tensor(595.8033, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([21.1942, 20.2058, 20.8001, 20.9205, 21.0627, 21.1701, 21.0068, 20.2394,\n",
            "        20.8000, 25.5311, 21.3560, 21.7680, 20.2159, 21.4101, 20.9416, 20.9804,\n",
            "        20.8119, 21.5693, 22.9894, 21.3354, 24.0024, 21.0679, 20.8281, 21.3526,\n",
            "        20.7405, 21.1667, 21.0994, 21.0668, 20.1107, 20.0820, 20.2720, 21.0779,\n",
            "        21.0669, 21.0566, 20.1058, 21.0890, 20.2105, 21.2451, 21.1301, 21.6814,\n",
            "        20.9593, 20.8597, 21.3934, 20.9164, 21.2468, 21.0326, 22.7287, 21.1051,\n",
            "        25.2447, 21.0535, 20.5221, 20.1332, 21.1059, 21.1004, 20.1365, 21.1033,\n",
            "        21.0033, 20.2244, 21.5506, 21.0859, 21.8900, 20.9054, 20.9300, 20.9488],\n",
            "       device='cuda:0')\n",
            "tensor([-6.7492e+00,  4.6023e+00,  1.8745e+00,  4.1716e+00,  4.1571e+00,\n",
            "        -6.8292e+00, -3.1044e+00, -6.3347e+00, -5.8556e+00, -4.4711e+00,\n",
            "        -1.1763e+01,  4.6471e+00, -5.1248e+00, -4.5593e+00, -3.1205e-01,\n",
            "         1.0248e+01, -2.6625e+00,  6.7919e-01,  3.9162e+00,  7.1610e+00,\n",
            "        -1.3654e+01,  4.0113e+00, -8.5625e-01, -1.2835e+01, -4.4511e+00,\n",
            "        -7.1949e+00, -4.4375e+00,  9.8798e+00, -1.0734e+00,  1.2761e+00,\n",
            "        -1.6522e+00, -6.5904e+00,  3.8419e+00, -6.6738e+00, -4.7291e+00,\n",
            "         7.1081e+00, -1.2195e+01, -6.6522e+00, -2.7313e+00,  4.1273e+00,\n",
            "        -2.8066e+00, -7.0731e+00,  1.1469e+01, -7.0593e+00, -6.9088e+00,\n",
            "        -4.3071e+00,  4.8435e+00, -5.6349e+00, -6.8069e+00, -6.4305e+00,\n",
            "        -4.4079e+00,  1.0965e+00,  3.7727e+00,  4.2162e-03, -6.9858e+00,\n",
            "        -4.5748e+00,  4.1272e+00, -6.6740e+00, -7.4286e+00, -2.9926e-01,\n",
            "        -1.5124e+01, -2.5513e-01, -6.8322e+00, -5.7088e+00], device='cuda:0')\n",
            "tensor(591.5740, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([20.9164, 21.0890, 21.0566, 21.4101, 21.0326, 21.2468, 21.3560, 20.9054,\n",
            "        21.5506, 20.8000, 20.8281, 21.0627, 21.3526, 20.8001, 20.1027, 25.2447,\n",
            "        21.0679, 21.0859, 20.9205, 21.1004, 20.2720, 21.2451, 21.1942, 21.5693,\n",
            "        20.2058, 20.8597, 20.9593, 24.0024, 20.9804, 21.8900, 20.1332, 21.0535,\n",
            "        22.7287, 21.0033, 20.0820, 21.1051, 20.9488, 21.0068, 20.2105, 20.1365,\n",
            "        21.1701, 21.3934, 20.5221, 20.9416, 22.9894, 20.8119, 21.7680, 21.1301,\n",
            "        21.0669, 25.5311, 21.1033, 21.0668, 21.0994, 21.0779, 20.2244, 20.9300,\n",
            "        20.1107, 21.1667, 20.2159, 20.1058, 20.7405, 21.6814, 21.3354, 21.1059],\n",
            "       device='cuda:0')\n",
            "tensor([-7.0593e+00,  7.1081e+00, -6.6738e+00, -4.5593e+00, -4.3071e+00,\n",
            "        -6.9088e+00, -1.1763e+01, -2.5513e-01, -7.4286e+00, -5.8556e+00,\n",
            "        -8.5625e-01,  4.1571e+00, -1.2835e+01,  1.8745e+00, -9.8159e-01,\n",
            "        -6.8069e+00,  4.0113e+00, -2.9926e-01,  4.1716e+00,  4.2162e-03,\n",
            "        -1.6522e+00, -6.6522e+00, -6.7492e+00,  6.7919e-01,  4.6023e+00,\n",
            "        -7.0731e+00, -2.8066e+00, -1.3654e+01,  1.0248e+01, -1.5124e+01,\n",
            "         1.0965e+00, -6.4305e+00,  4.8435e+00,  4.1272e+00,  1.2761e+00,\n",
            "        -5.6349e+00, -5.7088e+00, -3.1044e+00, -1.2195e+01, -6.9858e+00,\n",
            "        -6.8292e+00,  1.1469e+01, -4.4079e+00, -3.1205e-01,  3.9162e+00,\n",
            "        -2.6625e+00,  4.6471e+00, -2.7313e+00,  3.8419e+00, -4.4711e+00,\n",
            "        -4.5748e+00,  9.8798e+00, -4.4375e+00, -6.5904e+00, -6.6740e+00,\n",
            "        -6.8322e+00, -1.0734e+00, -7.1949e+00, -5.1248e+00, -4.7291e+00,\n",
            "        -4.4511e+00,  4.1273e+00,  7.1610e+00,  3.7727e+00], device='cuda:0')\n",
            "tensor(587.4860, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([20.9205, 21.3526, 21.0779, 21.3560, 20.9416, 20.1365, 21.0994, 21.0566,\n",
            "        21.1004, 21.7680, 21.5506, 20.1058, 20.8001, 21.3934, 20.9164, 21.0627,\n",
            "        21.0890, 25.2447, 21.0679, 21.1667, 20.8597, 20.5221, 20.8000, 21.1701,\n",
            "        25.5311, 20.2720, 20.0287, 21.1051, 22.7287, 21.2451, 21.8900, 21.1301,\n",
            "        24.0024, 21.0033, 20.2058, 20.9488, 20.9804, 20.9300, 20.1027, 20.8281,\n",
            "        20.8119, 21.0669, 20.1107, 20.2244, 21.0859, 21.1033, 21.3354, 20.2159,\n",
            "        20.2704, 20.1332, 20.0820, 21.0068, 21.6814, 21.4101, 20.2105, 21.0668,\n",
            "        20.9054, 20.9593, 21.5693, 21.2468, 21.1059, 20.7405, 21.0535, 22.9894],\n",
            "       device='cuda:0')\n",
            "tensor([ 4.1716e+00, -1.2835e+01, -6.5904e+00, -1.1763e+01, -3.1205e-01,\n",
            "        -6.9858e+00, -4.4375e+00, -6.6738e+00,  4.2162e-03,  4.6471e+00,\n",
            "        -7.4286e+00, -4.7291e+00,  1.8745e+00,  1.1469e+01, -7.0593e+00,\n",
            "         4.1571e+00,  7.1081e+00, -6.8069e+00,  4.0113e+00, -7.1949e+00,\n",
            "        -7.0731e+00, -4.4079e+00, -5.8556e+00, -6.8292e+00, -4.4711e+00,\n",
            "        -1.6522e+00,  7.7334e+00, -5.6349e+00,  4.8435e+00, -6.6522e+00,\n",
            "        -1.5124e+01, -2.7313e+00, -1.3654e+01,  4.1272e+00,  4.6023e+00,\n",
            "        -5.7088e+00,  1.0248e+01, -6.8322e+00, -9.8159e-01, -8.5625e-01,\n",
            "        -2.6625e+00,  3.8419e+00, -1.0734e+00, -6.6740e+00, -2.9926e-01,\n",
            "        -4.5748e+00,  7.1610e+00, -5.1248e+00, -6.5521e+00,  1.0965e+00,\n",
            "         1.2761e+00, -3.1044e+00,  4.1273e+00, -4.5593e+00, -1.2195e+01,\n",
            "         9.8798e+00, -2.5513e-01, -2.8066e+00,  6.7919e-01, -6.9088e+00,\n",
            "         3.7727e+00, -4.4511e+00, -6.4305e+00,  3.9162e+00], device='cuda:0')\n",
            "tensor(578.8560, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([20.0424, 21.1667, 21.0779, 21.1059, 20.2244, 20.1332, 22.9894, 21.7680,\n",
            "        20.8597, 20.9164, 20.8000, 21.3526, 25.2447, 20.0820, 21.0535, 20.1058,\n",
            "        20.1027, 21.0326, 20.2720, 21.6814, 20.9300, 20.9804, 20.9054, 21.2451,\n",
            "        21.2468, 21.3934, 20.2105, 21.1051, 20.5221, 20.9488, 20.1365, 22.7287,\n",
            "        20.2394, 20.9593, 21.0994, 21.0669, 20.8001, 21.1033, 21.0679, 21.4101,\n",
            "        21.5506, 21.0033, 21.1301, 20.0287, 21.1701, 20.1107, 21.0668, 21.0859,\n",
            "        21.3354, 24.0024, 20.9416, 20.2159, 25.5311, 20.2704, 21.1004, 20.8119,\n",
            "        21.0068, 21.3560, 20.8281, 21.0566, 21.0890, 20.2058, 21.1942, 21.0627],\n",
            "       device='cuda:0')\n",
            "tensor([-1.1716e+00, -7.1949e+00, -6.5904e+00,  3.7727e+00, -6.6740e+00,\n",
            "         1.0965e+00,  3.9162e+00,  4.6471e+00, -7.0731e+00, -7.0593e+00,\n",
            "        -5.8556e+00, -1.2835e+01, -6.8069e+00,  1.2761e+00, -6.4305e+00,\n",
            "        -4.7291e+00, -9.8159e-01, -4.3071e+00, -1.6522e+00,  4.1273e+00,\n",
            "        -6.8322e+00,  1.0248e+01, -2.5513e-01, -6.6522e+00, -6.9088e+00,\n",
            "         1.1469e+01, -1.2195e+01, -5.6349e+00, -4.4079e+00, -5.7088e+00,\n",
            "        -6.9858e+00,  4.8435e+00, -6.3347e+00, -2.8066e+00, -4.4375e+00,\n",
            "         3.8419e+00,  1.8745e+00, -4.5748e+00,  4.0113e+00, -4.5593e+00,\n",
            "        -7.4286e+00,  4.1272e+00, -2.7313e+00,  7.7334e+00, -6.8292e+00,\n",
            "        -1.0734e+00,  9.8798e+00, -2.9926e-01,  7.1610e+00, -1.3654e+01,\n",
            "        -3.1205e-01, -5.1248e+00, -4.4711e+00, -6.5521e+00,  4.2162e-03,\n",
            "        -2.6625e+00, -3.1044e+00, -1.1763e+01, -8.5625e-01, -6.6738e+00,\n",
            "         7.1081e+00,  4.6023e+00, -6.7492e+00,  4.1571e+00], device='cuda:0')\n",
            "tensor(576.6310, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([20.8001, 25.2447, 20.2244, 21.2468, 22.7287, 21.0535, 21.1301, 20.8000,\n",
            "        21.0668, 20.7405, 21.4101, 20.9593, 21.8900, 21.3526, 21.3934, 21.5506,\n",
            "        21.0994, 20.1332, 21.0033, 21.1059, 21.1004, 21.1667, 24.0024, 20.1027,\n",
            "        25.5311, 20.2394, 21.5693, 20.1058, 20.2105, 21.0068, 21.3354, 20.8281,\n",
            "        21.1942, 21.0859, 20.9164, 21.1701, 21.0669, 20.1107, 21.6814, 21.0679,\n",
            "        20.9205, 21.0326, 21.1051, 20.9804, 21.2451, 21.0779, 21.0627, 21.1033,\n",
            "        20.0287, 20.0424, 20.2058, 20.2720, 20.0820, 20.2704, 20.9300, 21.0566,\n",
            "        20.9054, 20.9416, 21.7680, 20.9488, 21.0890, 21.3560, 20.2159, 20.8597],\n",
            "       device='cuda:0')\n",
            "tensor([ 1.8745e+00, -6.8069e+00, -6.6740e+00, -6.9088e+00,  4.8435e+00,\n",
            "        -6.4305e+00, -2.7313e+00, -5.8556e+00,  9.8798e+00, -4.4511e+00,\n",
            "        -4.5593e+00, -2.8066e+00, -1.5124e+01, -1.2835e+01,  1.1469e+01,\n",
            "        -7.4286e+00, -4.4375e+00,  1.0965e+00,  4.1272e+00,  3.7727e+00,\n",
            "         4.2162e-03, -7.1949e+00, -1.3654e+01, -9.8159e-01, -4.4711e+00,\n",
            "        -6.3347e+00,  6.7919e-01, -4.7291e+00, -1.2195e+01, -3.1044e+00,\n",
            "         7.1610e+00, -8.5625e-01, -6.7492e+00, -2.9926e-01, -7.0593e+00,\n",
            "        -6.8292e+00,  3.8419e+00, -1.0734e+00,  4.1273e+00,  4.0113e+00,\n",
            "         4.1716e+00, -4.3071e+00, -5.6349e+00,  1.0248e+01, -6.6522e+00,\n",
            "        -6.5904e+00,  4.1571e+00, -4.5748e+00,  7.7334e+00, -1.1716e+00,\n",
            "         4.6023e+00, -1.6522e+00,  1.2761e+00, -6.5521e+00, -6.8322e+00,\n",
            "        -6.6738e+00, -2.5513e-01, -3.1205e-01,  4.6471e+00, -5.7088e+00,\n",
            "         7.1081e+00, -1.1763e+01, -5.1248e+00, -7.0731e+00], device='cuda:0')\n",
            "tensor(583.6560, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([21.0326, 21.0668, 21.0779, 21.3526, 20.9164, 21.7680, 20.8119, 20.1332,\n",
            "        21.0669, 20.9416, 20.3085, 20.2159, 21.8900, 25.2447, 20.2704, 20.9205,\n",
            "        21.1033, 20.9054, 21.3560, 20.8001, 21.1701, 20.7405, 20.9300, 21.5693,\n",
            "        21.2468, 22.7287, 20.0424, 20.0287, 21.0627, 21.6814, 20.2244, 21.0033,\n",
            "        20.2720, 20.9593, 21.1942, 20.1058, 21.2451, 20.1365, 21.0859, 21.0068,\n",
            "        21.1667, 20.9804, 21.0679, 25.5311, 20.5221, 21.1051, 22.9894, 21.0890,\n",
            "        20.8597, 21.1004, 21.3354, 20.2394, 20.9488, 24.0024, 21.5506, 20.0820,\n",
            "        21.1301, 20.2946, 21.3934, 21.0994, 21.1059, 20.2058, 21.4101, 20.1027],\n",
            "       device='cuda:0')\n",
            "tensor([-4.3071e+00,  9.8798e+00, -6.5904e+00, -1.2835e+01, -7.0593e+00,\n",
            "         4.6471e+00, -2.6625e+00,  1.0965e+00,  3.8419e+00, -3.1205e-01,\n",
            "        -1.2028e+00, -5.1248e+00, -1.5124e+01, -6.8069e+00, -6.5521e+00,\n",
            "         4.1716e+00, -4.5748e+00, -2.5513e-01, -1.1763e+01,  1.8745e+00,\n",
            "        -6.8292e+00, -4.4511e+00, -6.8322e+00,  6.7919e-01, -6.9088e+00,\n",
            "         4.8435e+00, -1.1716e+00,  7.7334e+00,  4.1571e+00,  4.1273e+00,\n",
            "        -6.6740e+00,  4.1272e+00, -1.6522e+00, -2.8066e+00, -6.7492e+00,\n",
            "        -4.7291e+00, -6.6522e+00, -6.9858e+00, -2.9926e-01, -3.1044e+00,\n",
            "        -7.1949e+00,  1.0248e+01,  4.0113e+00, -4.4711e+00, -4.4079e+00,\n",
            "        -5.6349e+00,  3.9162e+00,  7.1081e+00, -7.0731e+00,  4.2162e-03,\n",
            "         7.1610e+00, -6.3347e+00, -5.7088e+00, -1.3654e+01, -7.4286e+00,\n",
            "         1.2761e+00, -2.7313e+00, -3.3195e+00,  1.1469e+01, -4.4375e+00,\n",
            "         3.7727e+00,  4.6023e+00, -4.5593e+00, -9.8159e-01], device='cuda:0')\n",
            "tensor(569.4113, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([22.7287, 20.2105, 21.2451, 21.0627, 21.1051, 20.2704, 21.1033, 20.9593,\n",
            "        25.2447, 21.3560, 21.0679, 20.8119, 21.6814, 21.1059, 21.5693, 20.8597,\n",
            "        21.0890, 21.1004, 20.3085, 21.2468, 20.1365, 20.9804, 20.2394, 20.9300,\n",
            "        20.1058, 21.1301, 22.9894, 20.9054, 21.1942, 20.2058, 21.0669, 20.7405,\n",
            "        20.1027, 20.0424, 20.2159, 20.9488, 21.0326, 21.0994, 20.0287, 20.2244,\n",
            "        21.0535, 21.0068, 20.2946, 20.9416, 21.0779, 25.5311, 21.3934, 20.9205,\n",
            "        21.3526, 21.1701, 21.7680, 20.8281, 21.3354, 20.6110, 21.0566, 20.2720,\n",
            "        20.8000, 20.0820, 21.4101, 21.1667, 21.8900, 20.5221, 21.0859, 20.9164],\n",
            "       device='cuda:0')\n",
            "tensor([ 4.8435e+00, -1.2195e+01, -6.6522e+00,  4.1571e+00, -5.6349e+00,\n",
            "        -6.5521e+00, -4.5748e+00, -2.8066e+00, -6.8069e+00, -1.1763e+01,\n",
            "         4.0113e+00, -2.6625e+00,  4.1273e+00,  3.7727e+00,  6.7919e-01,\n",
            "        -7.0731e+00,  7.1081e+00,  4.2162e-03, -1.2028e+00, -6.9088e+00,\n",
            "        -6.9858e+00,  1.0248e+01, -6.3347e+00, -6.8322e+00, -4.7291e+00,\n",
            "        -2.7313e+00,  3.9162e+00, -2.5513e-01, -6.7492e+00,  4.6023e+00,\n",
            "         3.8419e+00, -4.4511e+00, -9.8159e-01, -1.1716e+00, -5.1248e+00,\n",
            "        -5.7088e+00, -4.3071e+00, -4.4375e+00,  7.7334e+00, -6.6740e+00,\n",
            "        -6.4305e+00, -3.1044e+00, -3.3195e+00, -3.1205e-01, -6.5904e+00,\n",
            "        -4.4711e+00,  1.1469e+01,  4.1716e+00, -1.2835e+01, -6.8292e+00,\n",
            "         4.6471e+00, -8.5625e-01,  7.1610e+00, -2.8625e+00, -6.6738e+00,\n",
            "        -1.6522e+00, -5.8556e+00,  1.2761e+00, -4.5593e+00, -7.1949e+00,\n",
            "        -1.5124e+01, -4.4079e+00, -2.9926e-01, -7.0593e+00], device='cuda:0')\n",
            "tensor(583.7535, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([21.1033, 21.3560, 21.0326, 20.9593, 20.2159, 21.3934, 21.0566, 21.0679,\n",
            "        20.2244, 21.4101, 24.0024, 20.9804, 21.0890, 25.2447, 21.1942, 21.2468,\n",
            "        20.9164, 21.0668, 21.1667, 21.0779, 20.2394, 21.0994, 22.7287, 20.2105,\n",
            "        20.1365, 21.5506, 21.2451, 21.0669, 20.9205, 20.0820, 20.2720, 20.8000,\n",
            "        20.1058, 21.8900, 21.0535, 20.0287, 21.1701, 20.8597, 21.1301, 20.4754,\n",
            "        21.0859, 20.9300, 20.1027, 20.9416, 21.6814, 20.1332, 21.3354, 20.3085,\n",
            "        20.6110, 21.1004, 20.5221, 21.1051, 21.0627, 20.7405, 20.2946, 20.2058,\n",
            "        21.1059, 20.8119, 21.3526, 21.0068, 21.0033, 20.9054, 21.7680, 20.2704],\n",
            "       device='cuda:0')\n",
            "tensor([-4.5748e+00, -1.1763e+01, -4.3071e+00, -2.8066e+00, -5.1248e+00,\n",
            "         1.1469e+01, -6.6738e+00,  4.0113e+00, -6.6740e+00, -4.5593e+00,\n",
            "        -1.3654e+01,  1.0248e+01,  7.1081e+00, -6.8069e+00, -6.7492e+00,\n",
            "        -6.9088e+00, -7.0593e+00,  9.8798e+00, -7.1949e+00, -6.5904e+00,\n",
            "        -6.3347e+00, -4.4375e+00,  4.8435e+00, -1.2195e+01, -6.9858e+00,\n",
            "        -7.4286e+00, -6.6522e+00,  3.8419e+00,  4.1716e+00,  1.2761e+00,\n",
            "        -1.6522e+00, -5.8556e+00, -4.7291e+00, -1.5124e+01, -6.4305e+00,\n",
            "         7.7334e+00, -6.8292e+00, -7.0731e+00, -2.7313e+00,  2.2169e+00,\n",
            "        -2.9926e-01, -6.8322e+00, -9.8159e-01, -3.1205e-01,  4.1273e+00,\n",
            "         1.0965e+00,  7.1610e+00, -1.2028e+00, -2.8625e+00,  4.2162e-03,\n",
            "        -4.4079e+00, -5.6349e+00,  4.1571e+00, -4.4511e+00, -3.3195e+00,\n",
            "         4.6023e+00,  3.7727e+00, -2.6625e+00, -1.2835e+01, -3.1044e+00,\n",
            "         4.1272e+00, -2.5513e-01,  4.6471e+00, -6.5521e+00], device='cuda:0')\n",
            "tensor(584.2585, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([25.5311, 20.1027, 21.1301, 24.0024, 21.1051, 21.0668, 20.4754, 21.0068,\n",
            "        20.2394, 20.2704, 20.9593, 21.2468, 21.1667, 21.0779, 21.6814, 20.2058,\n",
            "        21.4101, 21.0679, 20.9300, 20.8000, 20.8281, 21.1004, 20.2159, 20.0287,\n",
            "        21.1701, 20.2720, 20.0424, 21.5693, 20.9488, 20.7405, 20.1107, 20.1365,\n",
            "        21.3560, 21.0627, 21.2451, 25.2447, 20.5221, 21.0535, 21.1033, 20.0820,\n",
            "        21.1059, 20.9416, 20.2244, 21.0859, 20.1332, 20.9054, 20.1058, 20.6110,\n",
            "        20.9804, 21.0566, 22.9894, 21.0669, 21.0326, 20.8119, 22.7287, 20.9205,\n",
            "        20.8597, 20.8001, 20.3085, 21.7680, 21.0033, 21.5506, 21.1942, 21.0994],\n",
            "       device='cuda:0')\n",
            "tensor([-4.4711e+00, -9.8159e-01, -2.7313e+00, -1.3654e+01, -5.6349e+00,\n",
            "         9.8798e+00,  2.2169e+00, -3.1044e+00, -6.3347e+00, -6.5521e+00,\n",
            "        -2.8066e+00, -6.9088e+00, -7.1949e+00, -6.5904e+00,  4.1273e+00,\n",
            "         4.6023e+00, -4.5593e+00,  4.0113e+00, -6.8322e+00, -5.8556e+00,\n",
            "        -8.5625e-01,  4.2162e-03, -5.1248e+00,  7.7334e+00, -6.8292e+00,\n",
            "        -1.6522e+00, -1.1716e+00,  6.7919e-01, -5.7088e+00, -4.4511e+00,\n",
            "        -1.0734e+00, -6.9858e+00, -1.1763e+01,  4.1571e+00, -6.6522e+00,\n",
            "        -6.8069e+00, -4.4079e+00, -6.4305e+00, -4.5748e+00,  1.2761e+00,\n",
            "         3.7727e+00, -3.1205e-01, -6.6740e+00, -2.9926e-01,  1.0965e+00,\n",
            "        -2.5513e-01, -4.7291e+00, -2.8625e+00,  1.0248e+01, -6.6738e+00,\n",
            "         3.9162e+00,  3.8419e+00, -4.3071e+00, -2.6625e+00,  4.8435e+00,\n",
            "         4.1716e+00, -7.0731e+00,  1.8745e+00, -1.2028e+00,  4.6471e+00,\n",
            "         4.1272e+00, -7.4286e+00, -6.7492e+00, -4.4375e+00], device='cuda:0')\n",
            "tensor(564.1660, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([21.3560, 21.3934, 20.1365, 21.1004, 21.0994, 20.9593, 20.8000, 21.2451,\n",
            "        25.2447, 21.1059, 20.8281, 20.5221, 21.0535, 20.6110, 21.3526, 21.0779,\n",
            "        20.2394, 20.3085, 20.9164, 21.0068, 21.1051, 21.1667, 20.1332, 21.1301,\n",
            "        20.1027, 21.1942, 20.2946, 19.9050, 20.2159, 21.0033, 21.5693, 20.9054,\n",
            "        20.2105, 20.0424, 20.9488, 21.0859, 22.9894, 21.5506, 20.9300, 22.7287,\n",
            "        20.9416, 20.1826, 21.7680, 20.9804, 21.0679, 21.3354, 20.1107, 20.2244,\n",
            "        20.2720, 20.2058, 20.2704, 20.9205, 25.5311, 20.8001, 20.0820, 21.2468,\n",
            "        21.0326, 20.1058, 21.0668, 21.0890, 20.7405, 21.0627, 21.8900, 21.6814],\n",
            "       device='cuda:0')\n",
            "tensor([-1.1763e+01,  1.1469e+01, -6.9858e+00,  4.2162e-03, -4.4375e+00,\n",
            "        -2.8066e+00, -5.8556e+00, -6.6522e+00, -6.8069e+00,  3.7727e+00,\n",
            "        -8.5625e-01, -4.4079e+00, -6.4305e+00, -2.8625e+00, -1.2835e+01,\n",
            "        -6.5904e+00, -6.3347e+00, -1.2028e+00, -7.0593e+00, -3.1044e+00,\n",
            "        -5.6349e+00, -7.1949e+00,  1.0965e+00, -2.7313e+00, -9.8159e-01,\n",
            "        -6.7492e+00, -3.3195e+00, -4.7222e-01, -5.1248e+00,  4.1272e+00,\n",
            "         6.7919e-01, -2.5513e-01, -1.2195e+01, -1.1716e+00, -5.7088e+00,\n",
            "        -2.9926e-01,  3.9162e+00, -7.4286e+00, -6.8322e+00,  4.8435e+00,\n",
            "        -3.1205e-01, -6.9839e+00,  4.6471e+00,  1.0248e+01,  4.0113e+00,\n",
            "         7.1610e+00, -1.0734e+00, -6.6740e+00, -1.6522e+00,  4.6023e+00,\n",
            "        -6.5521e+00,  4.1716e+00, -4.4711e+00,  1.8745e+00,  1.2761e+00,\n",
            "        -6.9088e+00, -4.3071e+00, -4.7291e+00,  9.8798e+00,  7.1081e+00,\n",
            "        -4.4511e+00,  4.1571e+00, -1.5124e+01,  4.1273e+00], device='cuda:0')\n",
            "tensor(566.6671, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([21.0535, 20.0287, 21.2468, 21.0859, 21.3560, 19.6067, 24.0024, 22.9894,\n",
            "        20.1107, 21.0779, 20.0424, 21.1033, 21.3354, 20.2105, 20.9054, 21.1701,\n",
            "        20.1365, 21.5506, 21.0033, 20.0820, 25.5311, 20.9593, 20.2394, 20.2720,\n",
            "        20.3085, 21.5693, 21.0566, 20.2058, 20.8001, 20.9300, 21.0326, 20.2946,\n",
            "        22.7287, 21.0068, 20.7405, 21.0679, 20.1027, 21.2451, 20.8597, 20.2159,\n",
            "        20.2244, 21.1059, 21.4101, 20.5221, 20.1058, 21.3526, 20.9488, 20.6110,\n",
            "        21.1004, 19.9050, 20.8000, 20.8281, 20.9205, 21.1942, 20.4754, 21.0994,\n",
            "        21.1051, 21.8900, 20.9804, 21.0627, 21.0668, 21.0669, 21.7680, 20.9164],\n",
            "       device='cuda:0')\n",
            "tensor([-6.4305e+00,  7.7334e+00, -6.9088e+00, -2.9926e-01, -1.1763e+01,\n",
            "         3.5464e+00, -1.3654e+01,  3.9162e+00, -1.0734e+00, -6.5904e+00,\n",
            "        -1.1716e+00, -4.5748e+00,  7.1610e+00, -1.2195e+01, -2.5513e-01,\n",
            "        -6.8292e+00, -6.9858e+00, -7.4286e+00,  4.1272e+00,  1.2761e+00,\n",
            "        -4.4711e+00, -2.8066e+00, -6.3347e+00, -1.6522e+00, -1.2028e+00,\n",
            "         6.7919e-01, -6.6738e+00,  4.6023e+00,  1.8745e+00, -6.8322e+00,\n",
            "        -4.3071e+00, -3.3195e+00,  4.8435e+00, -3.1044e+00, -4.4511e+00,\n",
            "         4.0113e+00, -9.8159e-01, -6.6522e+00, -7.0731e+00, -5.1248e+00,\n",
            "        -6.6740e+00,  3.7727e+00, -4.5593e+00, -4.4079e+00, -4.7291e+00,\n",
            "        -1.2835e+01, -5.7088e+00, -2.8625e+00,  4.2162e-03, -4.7222e-01,\n",
            "        -5.8556e+00, -8.5625e-01,  4.1716e+00, -6.7492e+00,  2.2169e+00,\n",
            "        -4.4375e+00, -5.6349e+00, -1.5124e+01,  1.0248e+01,  4.1571e+00,\n",
            "         9.8798e+00,  3.8419e+00,  4.6471e+00, -7.0593e+00], device='cuda:0')\n",
            "tensor(579.9388, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([20.0287, 21.0668, 20.2720, 19.6067, 20.2058, 20.9804, 20.9416, 20.2244,\n",
            "        21.5506, 21.1942, 20.0820, 20.2394, 21.0627, 21.1301, 20.9164, 21.0679,\n",
            "        21.4101, 20.8281, 21.0566, 21.3560, 21.0669, 21.5693, 20.8001, 21.1051,\n",
            "        20.0424, 20.9593, 20.9205, 20.4754, 21.1701, 20.1027, 20.1826, 21.0326,\n",
            "        21.3526, 20.7405, 20.8597, 21.1667, 21.8900, 19.9050, 21.0068, 20.2105,\n",
            "        25.5311, 21.3934, 20.5221, 20.9054, 20.2704, 20.9300, 20.8000, 21.0890,\n",
            "        21.7680, 20.3085, 21.1059, 21.0994, 22.7287, 20.2946, 20.8119, 20.9488,\n",
            "        21.2468, 20.1107, 20.1365, 21.0779, 21.1033, 20.1058, 21.0859, 21.0535],\n",
            "       device='cuda:0')\n",
            "tensor([  7.7334,   9.8798,  -1.6522,   3.5464,   4.6023,  10.2482,  -0.3120,\n",
            "         -6.6740,  -7.4286,  -6.7492,   1.2761,  -6.3347,   4.1571,  -2.7313,\n",
            "         -7.0593,   4.0113,  -4.5593,  -0.8562,  -6.6738, -11.7626,   3.8419,\n",
            "          0.6792,   1.8745,  -5.6349,  -1.1716,  -2.8066,   4.1716,   2.2169,\n",
            "         -6.8292,  -0.9816,  -6.9839,  -4.3071, -12.8346,  -4.4511,  -7.0731,\n",
            "         -7.1949, -15.1238,  -0.4722,  -3.1044, -12.1953,  -4.4711,  11.4687,\n",
            "         -4.4079,  -0.2551,  -6.5521,  -6.8322,  -5.8556,   7.1081,   4.6471,\n",
            "         -1.2028,   3.7727,  -4.4375,   4.8435,  -3.3195,  -2.6625,  -5.7088,\n",
            "         -6.9088,  -1.0734,  -6.9858,  -6.5904,  -4.5748,  -4.7291,  -0.2993,\n",
            "         -6.4305], device='cuda:0')\n",
            "tensor(571.2509, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([21.0566, 20.8281, 20.2946, 21.3934, 20.8119, 21.5506, 20.8597, 21.5693,\n",
            "        21.3526, 20.9054, 20.1365, 20.2058, 20.9804, 21.0033, 20.9300, 20.1332,\n",
            "        21.2468, 20.2244, 21.1301, 21.1942, 21.0326, 21.0068, 21.0779, 20.2105,\n",
            "        21.2451, 21.0679, 20.2394, 21.4101, 25.2447, 21.8900, 21.0669, 20.1027,\n",
            "        21.1004, 20.7405, 21.1033, 21.0859, 20.0820, 20.2704, 21.3354, 20.1107,\n",
            "        20.9205, 20.0287, 21.0668, 20.2159, 20.8000, 21.6814, 20.8001, 22.7287,\n",
            "        21.0890, 21.7680, 20.5221, 25.5311, 19.9050, 21.0994, 18.8753, 20.9593,\n",
            "        22.9894, 20.9164, 21.3560, 21.1059, 20.3085, 20.9488, 21.1701, 21.0535],\n",
            "       device='cuda:0')\n",
            "tensor([-6.6738e+00, -8.5625e-01, -3.3195e+00,  1.1469e+01, -2.6625e+00,\n",
            "        -7.4286e+00, -7.0731e+00,  6.7919e-01, -1.2835e+01, -2.5513e-01,\n",
            "        -6.9858e+00,  4.6023e+00,  1.0248e+01,  4.1272e+00, -6.8322e+00,\n",
            "         1.0965e+00, -6.9088e+00, -6.6740e+00, -2.7313e+00, -6.7492e+00,\n",
            "        -4.3071e+00, -3.1044e+00, -6.5904e+00, -1.2195e+01, -6.6522e+00,\n",
            "         4.0113e+00, -6.3347e+00, -4.5593e+00, -6.8069e+00, -1.5124e+01,\n",
            "         3.8419e+00, -9.8159e-01,  4.2162e-03, -4.4511e+00, -4.5748e+00,\n",
            "        -2.9926e-01,  1.2761e+00, -6.5521e+00,  7.1610e+00, -1.0734e+00,\n",
            "         4.1716e+00,  7.7334e+00,  9.8798e+00, -5.1248e+00, -5.8556e+00,\n",
            "         4.1273e+00,  1.8745e+00,  4.8435e+00,  7.1081e+00,  4.6471e+00,\n",
            "        -4.4079e+00, -4.4711e+00, -4.7222e-01, -4.4375e+00, -2.3229e+00,\n",
            "        -2.8066e+00,  3.9162e+00, -7.0593e+00, -1.1763e+01,  3.7727e+00,\n",
            "        -1.2028e+00, -5.7088e+00, -6.8292e+00, -6.4305e+00], device='cuda:0')\n",
            "tensor(567.0079, device='cuda:0', requires_grad=True)\n",
            "########\n",
            "tensor([20.1365, 20.2058, 20.0820, 20.8281, 20.2244, 20.0287, 19.6067, 20.9416,\n",
            "        20.2105, 21.7680, 21.3934, 21.5506, 21.1301, 20.9164, 21.1942, 20.8597,\n",
            "        20.6110, 21.0535, 17.8270, 21.0994, 20.9054, 21.0668, 20.1826, 24.0024,\n",
            "        21.0627, 21.0068, 20.1107, 20.8000, 21.6814, 22.7287, 18.2903, 21.0679,\n",
            "        20.3085, 21.0859, 21.3354, 21.0669, 21.3560, 20.9593, 25.2447, 20.8119,\n",
            "        21.2468, 21.0033, 20.4754, 20.2946, 20.9300, 21.0779, 18.8753, 21.1701,\n",
            "        21.0326, 20.2159, 21.1051, 21.3526, 20.1058, 20.5221, 20.0424, 21.8900,\n",
            "        25.5311, 20.2704, 22.9894, 20.9804, 21.1004, 21.5693, 21.0566, 20.9205],\n",
            "       device='cuda:0')\n",
            "tensor([-6.9858e+00,  4.6023e+00,  1.2761e+00, -8.5625e-01, -6.6740e+00,\n",
            "         7.7334e+00,  3.5464e+00, -3.1205e-01, -1.2195e+01,  4.6471e+00,\n",
            "         1.1469e+01, -7.4286e+00, -2.7313e+00, -7.0593e+00, -6.7492e+00,\n",
            "        -7.0731e+00, -2.8625e+00, -6.4305e+00,  4.0723e+00, -4.4375e+00,\n",
            "        -2.5513e-01,  9.8798e+00, -6.9839e+00, -1.3654e+01,  4.1571e+00,\n",
            "        -3.1044e+00, -1.0734e+00, -5.8556e+00,  4.1273e+00,  4.8435e+00,\n",
            "        -7.7694e+00,  4.0113e+00, -1.2028e+00, -2.9926e-01,  7.1610e+00,\n",
            "         3.8419e+00, -1.1763e+01, -2.8066e+00, -6.8069e+00, -2.6625e+00,\n",
            "        -6.9088e+00,  4.1272e+00,  2.2169e+00, -3.3195e+00, -6.8322e+00,\n",
            "        -6.5904e+00, -2.3229e+00, -6.8292e+00, -4.3071e+00, -5.1248e+00,\n",
            "        -5.6349e+00, -1.2835e+01, -4.7291e+00, -4.4079e+00, -1.1716e+00,\n",
            "        -1.5124e+01, -4.4711e+00, -6.5521e+00,  3.9162e+00,  1.0248e+01,\n",
            "         4.2162e-03,  6.7919e-01, -6.6738e+00,  4.1716e+00], device='cuda:0')\n",
            "tensor(573.9806, device='cuda:0', requires_grad=True)\n",
            "########\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-f4134ffb9b47>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m                     \u001b[0;31m#NUOVO MODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0mnext_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                     \u001b[0mnext_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAMMA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#next_frame.max(dim=1, keepdim=True).values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                     \u001b[0;31m#target = reward + config.GAMMA * max(next_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/MachineLearningProject/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCZDvbZaAKye"
      },
      "source": [
        "## Example"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}